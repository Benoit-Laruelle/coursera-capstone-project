PART A. BUILD A BASELINE MODEL

1) DOWNLOAD AND CLEAN DATASET:

#!pip install numpy==1.21.4
#!pip install pandas==1.3.4
#!pip install keras==2.1.6

import pandas as pd
import numpy as np


2) DOWNLOAD THE DATA AND READ IT INTO A PANDAS DATAFRAME:

concrete_data = pd.read_csv('https://cocl.us/concreta_data')
concrete_data.head()

The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:
a. Cement
b. Blast Furnace Slag
c. Fly Ash
d. Water
e. Superplasticizer
f. Coarse Aggregate
g. Fine Aggregate


3) TO CHECK HOW MANY DATAPOINTS WE HAVE:

concrete_data.shape


4) TO CHECK THE DATASET FOR ANY MISSING VALUES:

concrete_data.describe()

concrete_data.isnull().sum()


5) SPLIT DATA INTO PREDICTORS AND TARGET:

concrete_data_columns = concrete_data.columns

predictors = concrete_data[concrete_data_columns[´Cement´,´Blast Furnace Slag´,´Fly Ash´,´Water´,´Superplasticizer´,´Coarse Aggregate´,´Fine Aggregate´,´Ageconcrete´]]
target = concrete_data['Strength'] # Strength column


6) TO DO A SANITY CHECK OF THE PREDICTORS AND THE TARGET DATAFRAMES:

predictors.head()

target.head()


PART B. NORMALIZE THE DATA

7) NORMALIZE THE DATA BY SUBTRACTING THE MEAN AND DIVIDING BY THE STANDARD DEVIATION:

predictors_norm = (predictors - predictors.mean()) / predictors.std()
predictors_norm.head()


8) SAVE THE NUMBER OF PREDICTORS TO n_cols WE WILL NEED THIS NUMBER WHEN BUILDING OUR NETWORK:

n_cols = predictors_norm.shape[1] # number of predictors


9) IMPORT KERAS LIBRARY: (TENSOR FLOW BACKEND IS USED TO INSTALL THE KERAS LIBRARY)

import keras
from keras.models import Sequential
fromkeras.layers import Dense


10a) BUILD A NEURAL NETWORK: (REGRESSION MODEL THAT HAS 1 HIDDEN LAYER, OF 10 NODES, ReLu ACTIVATION FUNCTION, ADAM OPTIMIZER, MEAN SQUARED ERROR AS THE LOSS FUNCTION)

def regression_model():

model = sequential()

n_cols = concrete_data.shape[1]

model.add(Dense(10, activation=´relu´, input_shape=(n_cols,)))
model.add(Dense(1))

model.compile(optimizer=´adam´, loss=´mean_square_error´)


PART D. INCREASE THE NUMBER OF HIDDEN LAYERS

10b) BUILD A NEURAL NETWORK: (REGRESSION MODEL THAT HAS 3 HIDDEN LAYERS, EACH OF 10 NODES, ReLu ACTIVATION FUNCTION, ADAM OPTIMIZER, MEAN SQUARED ERROR AS THE LOSS FUNCTION)

def regression_model():

model = sequential()

n_cols = concrete_data.shape[1]

model.add(Dense(10, activation=´relu´, input_shape=(n_cols,)))
model.add(Dense(1))

model.compile(optimizer=´adam´, loss=´mean_square_error´)


11a) TRAIN AND TEST THE NETWORK (USING THE FIT METHOD. LEAVE OUT 30% OF THE DATA FOR VALIDATION AND TRAIN THE MODEL FOR 50 EPOCHS)

model = regression_model()

model.fit(predictors_norm, target, validation_split=0.3, epochs=50, verbose=2)


PART C. INCREASE THE NUMBER OF EPOCHS

11b) TRAIN AND TEST THE NETWORK (USING THE FIT METHOD. LEAVE OUT 30% OF THE DATA FOR VALIDATION AND TRAIN THE MODEL FOR 100 EPOCHS)

model = regression_model()

model.fit(predictors_norm, target, validation_split=0.3, epochs=100, verbose=2)


12) PREDICTION / EVALUATION:

predictions = model.predict(test_data)









